\documentclass[a4paper,14pt]{article}
\input{preamble.tex}

\title{Программа к экзамену по курсу "Алгоритмы и структуры данных"}
\date{}

\begin{document}
    \maketitle
    \newpage
    \tableofcontents
    \newpage

    \section{(1) Префикс-функция. Линейный алгоритм подсчета. Алгоритм Кнута-Морриса-Прата.}
    
    \begin{Def}
        Строка $T$ называется супрефиксом строки $S$, если она является
одновременно и префиксом, и суффиксом строки $S$.
    \end{Def}
    \begin{note}
        Пустая строка всегда является супрефиксом любой строки
(кроме пустой).
    \end{note}
    \begin{Def}
        Префикс-функцией от строки $S$ называют такой массив $\pi(S)$
длины $|S|$, что $\pi(S)[i]$ равно длине максимального несобственного (то
есть не равного всей строке) супрефикса строки $S[: i + 1]$.
    \end{Def}
    \begin{prop}
        $\pi[i+1]\leqslant \pi[i]+1$
    \end{prop}
    \begin{proof}
        Рассмотрим подстроку вида суффикс строки $S[: i + 2]$ длины $\pi[i + 1]$.
Удалив последний символ этой подстроки, мы получим суффикс,
оканчивающийся на позиции $i$ и имеющий длину $\pi[i + 1] - 1 \leqslant \pi[i]$.
    \end{proof}

    \subsection*{Линейный алгоритм подсчета.}
    Пусть $\forall j\leqslant i$ известно $\pi[j]$. Подсчитаем $\pi[i+1]$:
    \begin{itemize}
        \item $S[i+1]=S[\pi[i]] \Rightarrow \pi[i+1]=\pi[i]+1$.
        \item $S[i+1]\ne S[\pi[i]]$. Цель - максимальный по длине супрефикс,
        заканчивающийся в $(i + 1)$-й позиции. Такой супрефикс состоит
        из какого-то супрефикса строки $S[: i + 1]$ и символа $S[i + 1]$.
        Переберем все супрефиксы $S[: i + 1]$ в порядке вложенности, пусть
        они имеют длины $j_1 > j_2 > \dots > j_k$, тогда $\pi[i + 1] = j_l + 1$, где $j_l$
        таков, что $S[j_l + 1] = S[i + 1]$
    \end{itemize}

    \begin{prop}
        Супрефиксы строки $S$ в порядке вложенности имеют длины $\pi[|S|-1], \pi[\pi[|S|-1]-1], \pi[\pi[\pi[|S|-1]-1]-1], \dots$ 
    \end{prop}

    \begin{lstlisting}
Array<int> PrefixFunction(String s) {
    Array<int> pi_func(len(s), 0);
    for (int i = 1; i < len(s); ++i) {
        int k = pi_func[i - 1];
        while (k > 0 and s[i] != s[k]) { k = pi_func[k - 1]; }
        pi_func[i] = k;
        if (s[i] == s[k]) { ++pi_func[i]; }
    }
 return pi_func;
}
    \end{lstlisting}
    Так как k может увеличиться не более чем на 1, значит оно не больше
    $|S| - 1$. А внутри while оно убывает, значит суммарное число
    итераций while не превосходит $|S| - 1$. \\
    Таким образом, время работы: $O(|S|)$.

    \subsection*{Алгоритм Кнута-Морриса-Прата.}
    Требуется найти все позиции, начиная с
которых $P$ входит в $T$. \\
    \begin{enumerate}
        \item $S=P\#T$
        \item Вычислим префикс функцию.
        \item $\pi[i]=|P| \Rightarrow$ нашли конец вхождения.
    \end{enumerate}

    \section{(1) Z-функция. Линейный алгоритм подсчета. Алгоритм Кнута-Морриса-Прата.}
    
    \begin{Def}
        Z-функцией от строки $S$ называют такой массив $z(S)$ длины $|S|$,
что $z(S)[i]$ равно длине максимального префикса начинающегося
$S[i :]$, который одновременно является и префиксом всей строки $S$.
    \end{Def}
    \begin{example}
        \[
        \operatorname{zet\_func}(\texttt{abcdabscabcdabia})
        = [0, 0, 0, 0, 2, 0, 0, 0, 6, 0, 0, 0, 2, 0, 0, 1]
        \]
        \end{example}
        
    \subsection*{Линейный алгоритм подсчета.}
    \begin{Def}
        Z-блоком назовем подстроку с началом в позиции $i$ и длиной $z[i]$.
    \end{Def}
    Будем поддерживать Z-блок строки $S$ с максимальной позицией конца
(среди них наибольший по длине), обозначим его границы за $left,right$.
Пусть $\forall j<i$ известно $z[j]$. Подсчитаем $z[i]$:
    \begin{itemize}
        \item Пусть $i > right$, тогда наивно идем по строке S и сравниваем
        $S[i + j]$ и $S[j]$. Пусть $j$ первая позиция в строке $S$ для которой не
        выполняется равенство $S[i + j] = S[j]$, тогда $z[i] = j$. Тогда
        $left = i, right = i + j - 1$.
        \item Пусть $i \leqslant \textit{right}$, тогда сравним $z[i-\textit{left}] + i$ и
        $\textit{right}$.
        \begin{itemize}
            \item Если $\textit{right} < z[i-\textit{left}] + i$, то наивно идём по строке,
            начиная с $\textit{right}$, и вычисляем значение $z[i]$.
            \item Иначе мы уже знаем верное значение $z[i]$, так как оно равно
            значению $z[i-\textit{left}]$.
        \end{itemize}
    \end{itemize}
\newpage
    \begin{lstlisting}
Array<int> ZetFunction(String s) {
    Array<int> z(len(s), 0);
    int left = 0, right = 0;
    for (int i = 1; i < len(s); ++i) {
        z[i] = max(0, min(right - i, z[i - left]));
        while (s[z[i]] == s[i + z[i]] and i + z[i] < len(s)) {
            ++z[i];
        }
        if (i + z[i] > right) { left = i, right = i + z[i]; }
    }
    return z;
    
}
    \end{lstlisting}
    Заметим, что данный алгоритм обращается к каждому символу строки
не более двух раз: когда наивно насчитываем $zet\_func[i]$ и когда он
только попадает в $[left,right]$. \\
Поэтому время работы: $O(|S|)$.
\subsection*{Алгоритм Кнута-Морриса-Прата.}
    Требуется найти все позиции, начиная с
которых $P$ входит в $T$. \\
    \begin{enumerate}
        \item $S=P\#T$
        \item Вычислим Z-функцию.
        \item $z[i]=|P| \Rightarrow$ нашли начало вхождения.
    \end{enumerate}

    \section{(1) Полиномиальное хеширование. Алгоритм Рабина-Карпа.}
    \begin{Def}
        Полиномиальная хеш-функция для строки S определяется как
        \[
            h(S)=\left(\sum_{i=0}^{|S|-1} S[i]\cdot x^i\right) \mod p
        \]
        где p -- простое число, а $x\in \ZZ_p^*$.
    \end{Def}
    \begin{note}
        \[h(Sc)=\left(\sum_{i=0}^{|S|-1} S[i]\cdot x^i\right) \mod p+c\cdot x^{|S|} \mod p=(h(S)+c\cdot x^{|S|}) \mod p\]
    \end{note}
    \begin{prop}
        Пусть $h[i]=h(S[:i+1])$, тогда
        \[h(S[l:r])=\frac{h[r-1]-h[l-1]}{x^l}\]
    \end{prop}

    \subsection*{Алгоритм Рабина-Карпа.}
    \begin{enumerate}
        \item Посчитаем полиномиальный хеш паттерна за $O(|P|)$.
        \item Посчитаем массив префиксных хешей текста $T$ за $O(|T|)$.
        \item Переберем в тексте все подстроки размера $|P|$ (их $O(|T|)$) и для
        каждой сравним хеш с хешом $P$. Если не совпали, то точно в
        данном месте вхождения нет, иначе проверяем в лоб.
    \end{enumerate}

    \begin{theorem}[б/д]
        Полиномиальная хеш-функция выше гарантирует, что вероятность
коллизии не превосходит $\frac{|P|-1}{|P|}$
    \end{theorem}

    \begin{corollary}
        Время работы в среднем: $O(|P|+|T|)$.
    \end{corollary}

    \section{(1) Бор. Сравнительный анализ времени работы в зависимости от выбора контейнера для хранения
    дочерних вершин.}
    \begin{Def}
        Бор - структура данных для хранения набора строк,
представляющая из себя подвешенное дерево с символами на рёбрах.
Строки получаются последовательной записью всех символов,
хранящихся на рёбрах между корнем бора и терминальной вершиной.
    \end{Def}
    \begin{table}[h]
        \centering
        \begin{tabular}{|c|c|c|c|}
            \hline
            \textbf{Контейнер} & \textbf{Построение} & \textbf{Поиск} & \textbf{Память} \\
            \hline
            vector
            & $O\!\left(\sum_{w \in \textit{dict}} |w|\right)$
            & $O\!\left(|S|\right)$
            & $O\!\left(|\Sigma| \sum_{w \in \textit{dict}} |w|\right)$ \\
            \hline
            map
            & $O\!\left(\log |\Sigma| \sum_{w \in \textit{dict}} |w|\right)$
            & $O\!\left(|S|\log |\Sigma|\right)$
            & $O\!\left(\sum_{w \in \textit{dict}} |w|\right)$ \\
            \hline
            hashmap
            & $O\!\left(\sum_{w \in \textit{dict}} |w|\right)$
            & $O\!\left(|S|\right)$
            & $O\!\left(\sum_{w \in \textit{dict}} |w|\right)$ \\
            \hline
        \end{tabular}
    \end{table}
    \section{(3) Суффиксный массив. Построение за $O(|S|\log |S|)$.}
    \begin{Def}
        Суффиксный массив - индексы начал суффиксов, отсортированные в лексикографическом порядке.
    \end{Def}
    Добавим в конец \#, зациклим и будем сортировать все подстроки.
    \subsection*{Построение за $O(|S|\log |S|)$.}
    \begin{enumerate}
        \item Сортируем все подчтроки длинны 1 (подсчетом).
        \item Знаем перестановку - массив $p$. Подсчетаем $c$ - номера классов эквивалентности: идем по $p$, увеличиваем класс,
        если текущий символ в перестановке $p$ не равен предыдущему.
        \item Пусть известна сортировка для $2^k$. Отсортируем подстроки $2^{k+1}$ следующим образом:
        \begin{enumerate}
            \item Разобьем подстроки длины $2^{k+1}$ на две части: первые $2^k$ символов и вторые $2^k$ символов.
            \item Каждую подстроку длины $2^{k+1}$ представим как пару $(c[i], c[i+2^k])$.
            \item Отсортируем пары $(c[i], c[i+2^k])$ лексикографически (подсчетом, сначала по второму, потом по первому).
        \end{enumerate}
        \item Пересчетаем $p$: $p[i]=p[i]-2^k$. Повторяем 2-3. Только в шаге 2 классы эквивалентности не по строки, а по $c$.
        \item $p$ - суффиксный массив
    \end{enumerate}

    \section{(3) Понятие \texttt{LCP}. Массив \texttt{lcp}. Алгоритм Касаи-Аримуры-Арикавы-Ли-Пака построения lcp
    (корректность б/д). Поиск \texttt{LCP} с использованием массива \texttt{lcp} и решения задачи \texttt{RMQ}.}
    \begin{Def}
        LCP - longest common prefix. LCP(S, T) - длина наибольшего общего префикса строки $S$ и $T$.
    \end{Def}
    \begin{Def}
        $lcp[i]$ - длина LCP $i$-го и $i+1$-го суффикса в лексикографическом порядке (суффмас).
    \end{Def}
    \subsection*{Алгоритм Касаи-Аримуры-Арикавы-Ли-Пак.}
    Дана строка $S$ и ее суффиксный массив $p$.
    \begin{enumerate}
        \item Находим $pos$ - обратный к $p$.
        \item Иницилизируем $k=0$. Для $i\in \overline{0, n-1}$
        \begin{itemize}
            \item $pos[i] == 0 \Rightarrow$ continue
            \item Иначе:
            \begin{itemize}
                \item $i=p[pos[i]-1]$
                \item пока $s[i+k]==s[j+k] \Rightarrow k++$
                \item $lcp[pos[i]]=k$
                \item $k>0 \Rightarrow k++$
            \end{itemize}
        \end{itemize}
    \end{enumerate}
    \subsection*{Поиск \texttt{LCP} с использованием массива \texttt{lcp} и решения задачи \texttt{RMQ}.}
    \begin{prop}
        Пусть $pos[l]<pos[r]$. Тогда \[LCP(S[l:], S[r:])=min\left(lcp[pos[l]], lcp[pos[l]+1], \dots, lcp[pos[r]]-1\right)\]
    \end{prop}

    \section{(1) Суффиксные ссылки в боре. Функция перехода. Алгоритм Ахо-Корасик построения суффиксных ссылок.}
    \begin{note}
        $[u]$ - слово, которое составляет путь от корня до вершины u в боре.
    \end{note}
    \begin{Def}
        Суффиксной ссылкой вершины u называют такую вершину
$v = link(u)$, что $[v]$ является максимальным по длине суффиксом $[u]$,
который можно прочесть, идя по бору из корня до, быть может, не
терминальной вершины.
    \end{Def}
    \begin{note}
        Суффиксная ссылка для корня в общем случае не определена. Доопределим ее вершиной NIL.
    \end{note}
    \subsection*{Алгоритм Ахо-Корасик построения суффиксных ссылок.}
    \begin{Def}
        Введем функцию $to(u, c)$, равную вершине, куда из вершины u
можно перейти по букве c. Определяется она следующим образом:
        \[
\mathrm{to}(u, c) =
\begin{cases}
\mathrm{vertex}([u] + c), & \text{если из вершины $u$ есть переход по $c$,} \\
\mathrm{to}(\mathrm{link}(u), c), & \text{если из вершины $u$ нет перехода по $c$.}
\end{cases}
\]
    \end{Def}
    \begin{prop}
        Если переход из u по букве c есть в боре, то $\mathrm{link}(\mathrm{vertex}([u]+c))=\mathrm{vertex}[to(\mathrm{link}(u), c)]$
    \end{prop}
    \subsection*{Алгоритм.}
    \begin{enumerate}
        \item Строим бор на данном наборе слов.
        \item С помощью BFS из корня насчитаем функции $link$ и $to(\cdot, c)$ по
        утверждению выше.
    \end{enumerate}
    Почему это работает? Из соотношения выше напрямую следует, что
данные функции можно насчитать через вершины выше, чем текущая.
А по предположению индукции мы верили, что для всех выше все
посчитано корректно. База индукции - корень. Для него ручками
посчитаем все по определению.

    \section{Сжатые суффиксные ссылки. Автомат Ахо-Корасик. Поиск множества паттернов в тексте.}

    \begin{Def}
        Сжатой суффиксной ссылкой вершины $u$ называют такую вершину $v = comp(u)$, что
        \[
        \mathrm{comp}(u) =
        \begin{cases}
        \mathrm{link}(u), & \text{если $\mathrm{link}(u)$ терминальная,} \\
        \mathrm{comp}(\mathrm{link}(u)), & \text{иначе.}
        \end{cases}
        \]
    \end{Def}

    \subsection*{Поиск множества паттернов в тексте.}
    \begin{enumerate}
        \item Построем Ахо-Корасик на паттернах за $O\left(|\Sigma|\sum_{i=1}^k |P_i|\right)$
        \item Теперь будем идти по функции $to$ текстом $T$ из корня за $O(|T|)$.
        \item При очередном переходе будем прыгать по сжатым суффиксным
        ссылкам вверх и насчитывать вхождения.
    \end{enumerate}
    \textbf{Время:} $O\left(|\Sigma|\sum_{i=1}^k |P_i|+|T|+k\right)$, где $k$ -- кол-во вхождений.

    \section{Понятие правого контекста. Классы эквивалентности по равенству правых контекстов. Теорема
    Майхилла-Нероуда (б/д). Определение суффиксного автомата.}
    \begin{Def}
        Правый контекст слова $x$ для языка $L$ называют множество
        \[R_L(x)=\{w|xw\in L\}\]
    \end{Def}
    \begin{Def}
        Два слова эквивалентны относительно языка $L$, то есть $x\sim_L y$, если $R_L (x)=R_L (y)$.
    \end{Def}
    \begin{theorem}[Майхилла-Нероуда]
        Если в языке $L$ конечное число классов эквивалентности, равное $k$, то
        \begin{enumerate}
            \item Язык автоматный и в любом ДКА, распознающем данный язык,
            хотя бы $k$ состояний
            \item Существует ДКА, распознающий $L$, в котором ровно $k$ состояний,
            где каждое состояние отвечает за соответствующий класс
            эквивалентности
        \end{enumerate}
    \end{theorem}

    \begin{Def}
        Суффиксным автоматом для строки $S$ назовем минимальный по числу состояний ДКА, распознающий язык суффиксов $L$.
    \end{Def}
    \begin{note}
        Далее будем считать, что речь идет только о подстроках $S$, а
вместо языка $L$ будем обозначать эквивалентность по языку $S$,
порожденному суффиксами строки $S$.
    \end{note}

    \section{Атрибуты состояний. Устройство класса эквивалентности.}
    \begin{prop}
        Если $x\sim_L y$, то либо $x$ суффикс $y$, либо $y$ суффикс $x$
    \end{prop}
    \begin{proof}
        $\exists z: \ xz\in L, yz \in L$.
    \end{proof}
    \begin{Def}
        $longest(v)$ - самая длинная строка, которую можно прочесть,
дойдя до состояния v в суффиксном автомате.
    \end{Def}
    \begin{Def}
        $len(v)$ - длина $longest(v)$.
    \end{Def}
    \begin{Def}
        $link(v)$ - такая вершина, что в ней лежит самый длинный
суффикс $longest(v)$, не лежащий в $v$.
    \end{Def}
    \begin{prop}
        Пусть $v$ - вершина автомата. Тогда в $v$ лежат $longest(v)$ и несколько
её самых длинных суффиксов.
    \end{prop}
    \begin{proof}
        $C$ - класс эквивалентности вершины $v$. \\
        Пусть $u=longest(v)$. Тогда $\forall x\in C: R_L (x)=R_L (u) \Rightarrow x$ суффикс $u$. \\
        Пусть $y$ - самая короткая строка в $C$. Пусть $w$ суффикс $u (|y|<|w|<|u|)$. Тогда $R_L (u)\subseteq R_L (w) \subseteq R_L (y)$,
        а $R_L (u)=R_L (y) \Rightarrow R_L (u) = R_L (w) = R_L (y)$ 
    \end{proof}
    
    \section{Понятие longest. Критерий longest. Устройство ребер в суффиксном автомате.}

    Определения - см. предыдущий пункт.
    
    Автомат состоит из:
    \begin{enumerate}
        \item Вершины - классы эквивалентности.
        \item Ребра - это тройки $(C_1, C_2, d)$.
        \item В правом контексте начальной вершины - все суффиксы.
        \item В правом контексте конечной вершины есть $\varepsilon$.
    \end{enumerate}

    \begin{prop}
        Если $u, v \in C_1 \Rightarrow ud, vd \in C_2$.
    \end{prop}
    \begin{proof}
        Пусть $z\in R_L (ud)$. Тогда $udz$ - суффикс $s \Rightarrow dz\in R_L (u)=R_L (v) \Rightarrow z\in R_L (vd)$.  
    \end{proof}

    \begin{prop}[Критерий longest]
        Пусть $u$ - подстрока $S$. Тогда $u=longest([u]) \Leftrightarrow$ либо $u$ - префикс $S$, либо $\exists a\ne b: au, bu$ - подстроки $S$.
    \end{prop}
    \begin{proof}
        \begin{enumerate}
            \item Пусть $u\ne longest([u])$. Тогда $\exists d: \ du\sim_L u$. Значит, перед любым вхождением $u$ в $S$ стоит $d$.
            \item Пусть $u=longest([u])$, $u$ - не префикс $S$. Рассмотрим символы, предшедствующие всем вхождениям $u\sim_L cu$. Противоречие.
        \end{enumerate}
    \end{proof}
    \begin{corollary}
        Если $u$ была longest в $S$, то она останется longest в $Sc$. Могут только появляться новые, гарантированно $Sc$.
    \end{corollary}

    \begin{prop}
        Пусть в автомате есть ребра $u_1 \rightarrow v, u_2 \rightarrow v, \dots u_k \rightarrow v$ и $len(u_i)>len(u_{i+1})$.
        Тогда
        \begin{enumerate}
            \item Все ребра идут по одной букве $c$.
            \item $link(u_i)=u_{i+1}$.
        \end{enumerate}
    \end{prop}
    \begin{proof}
        Рассмотрим слова в классе $v$. Они заканчиваются на $c$. \\
        Класс разбивается на ячейки $1\dots k$. Каждой вершине $u_i$ соответствует ячейка.
    \end{proof}
    
    \section{Новые состояния в суффиксном автомате при дописывании символа. Алгоритм построения
    суффиксного автомата: случаи 1 (новая буква) и 2 (без порождения clone).}
    Классы эквивалентности $\Leftrightarrow$ все longest.
    \begin{prop}
        При дописывании символа c к строке S образуется не более двух
новых состояний:
        \begin{enumerate}
            \item Состояние, у которого $longest(v) = Sc$, которое обязательно
            появится.
            \item Состояние $[T]$, где $T = longest([T]_{Sc} )$ - самый длинный суффикс
            $Sc$, который является подстрокой $S$ (необязательно
            появится).
        \end{enumerate}
    \end{prop}
    \begin{proof}
        \begin{enumerate}
            \item Так как $Sc$ - префикс $Sc$, значит, по критерию longest,
            $Sc = longest([Sc]_{Sc})$.
            \item Если $T$ не подстрока $S$, то она не могла быть рассмотрена ранее и
            обязательно попадет в $[Sc]_Sc$. Значит $T$ - суффикс $Sc$, который
            является подстрокой S. \\ 
            По критерию $longest$, чтобы $T$ оказалась новым longest, у нее
обязано появиться вхождение с новым предварением. Иначе
нового состояния не возникнет в автомате.
        \end{enumerate}
    \end{proof}

    \begin{prop}
        $link([Sc]_{Sc})=[T]_{Sc}$, где $T$ из утверждения выше.
    \end{prop}

    \section*{Алгоритм построения.}
    Алгоритм будет итеративным: перестраивание автомата при
дописывании по одному символу. Потенциальные изменения:
    \begin{enumerate}
        \item Ребра, ведущие в $[Sc]_{Sc}$ . (Ребер из нее быть не может по
        соображениям длины пути и строки $Sc$).
        \item При возникновении нового состояния $T$, ребра, ведущие в/из
        него.
    \end{enumerate}
    Осталось разобраться с тремя возможными ситуациями.
    \subsection*{Случай 1 (новая буква).}
    Должно появиться ребро $([S]_{Sc} , c) \rightarrow [Sc]_Sc$.\\
По утверждению об устройстве ребер в одну вершину, все такие ребра
бедутся из вершин, образующих суффиксный путь. Тогда, прыгая по
суффиксным ссылкам из $[S]_S$ , проводим ребра, пока не доберемся до
вершины, из которой есть переход по $c$. \\
Допустим, что пришли в $q_0$, из которого нет ребра по букве $c$, тогда не
было буквы $c$ в $S$ и при этом $link([Sc]_{Sc} ) = q_0$. \\
    \subsection*{Случай 2 (без расщепления).}
    Пусть пришли в $p$, откуда есть ребро в $q$ по $c$. \\
    Из обозначений выше $T = longest(p) + c$. Вершину $q$ надо будет
расщепить, если $T \ne longest(q)$. Таким образом, критерий
расщепления: $len(q) > len(p) + 1$. \\
Допустим, что не надо расщеплять, то есть $len(q) = len(p) + 1$. Тогда
достаточно провести $link([Sc]_{Sc} ) = q$. На этом обработка окончена.
    \subsection*{Случай 3 (с расщеплением).}
    Теперь $len(q) > len(p) + 1$. Тогда появится новое состояние clone
такое, что $longest(clone) = T = longest(p) + c$, при этом в $q$ будут
лежать суффиксы $longest(q)$, которые длиннее $T$. \\
Рассмотрим суффиксный путь из p. Надо пропрыгать по нему, пока
ребра по букве c шли в $q$, и перенаправить их в $clone$. \\
Заметим, что $R_{Sc} (clone) = R_{Sc} (q) \cup \{\varepsilon\}$, значит переходы из clone
совпадут с переходами из q. \\
Остались ссылки. $link([Sc]_{Sc} ) = clone, link(clone) = link(q),
link(q) = clone, len(clone) = len(p) + 1$.

    \section{Алгоритм построения суффиксного автомата: все случаи.}
    См. предыдущий пункт.

    \section{Время построения суффиксного автомата.}
    \begin{prop}
        При $|S|\geqslant 2$ число состояний в автомате не превосходит $2|S|-1$.
    \end{prop}
    \begin{proof}
        Индукция по длине $S$. Для строки из двух букв число состояний равно
трем. Далее дописывание одной буквы увелиичвает не более чем на
два.
    \end{proof}
    \begin{theorem}[б/д]
        Начиная с некоторого $n$, в суффиксном автомате для строки длины $n$
число ребер не превосходит $3n - 4$.
    \end{theorem}

    Заметим, что случаи первого и второго типов не меняют старых
ребер, а только добавляют новые, которых $O(|S|)$. То есть они
работают суммарно за $O(|S|)$. \\
    Потенциал $\Phi$ - число вершин на пути по суфф. ссылкам от максимальной. Он уменьшается $\Rightarrow O(|S|)$.

    \section{Задача интерполяции. Матричная постановка, существование и единственность решения. Комплексные корни из единицы. Обратная к матрице Вандермонда на комплексных корнях из единицы.}
    \begin{problem}
        Известно, что многочлен $P(x)=a_0+a_1 x+\dots a_{n-1}x^{n-1}$ в различных точках $x_0, x_1, \dots, x_{n-1}$ принимает значения $y_0, y_1, \dots, y_{n-1}$.
        Надо восстановить многочлен $P(x)$, то есть найти $a_i$
    \end{problem}

        Заметим, что перед нами система уравнений вида
    \[
    P(x_i) = a_0 + a_1 x_i + \dots + a_{n-1} x_i^{\,n-1} = y_i.
    \]

    Тогда данную систему уравнений можно записать в матричном виде
    \[
    Xa = y,
    \]
    где
    \[
    y = (y_0, \dots, y_{n-1})^{T}, \quad
    a = (a_0, \dots, a_{n-1})^{T}, \quad
    X = \bigl(x_i^{\,j}\bigr)_{i,j=0}^{n-1}.
    \]

    Формально решение можно записать в виде
    \[
    a = X^{-1} y,
    \]
    однако возникает вопрос: существует ли вообще матрица \(X^{-1}\)?

    \begin{theorem}[Вандермонда (б/д)]
        Рассмотрим матрицу
    \[
    X = \bigl(x_i^{\,j}\bigr)_{i,j=0}^{n-1}.
    \]
    Тогда
    \[
    \det(X) = \prod_{0 \le j < i < n} (x_i - x_j).
    \]
    \end{theorem}

    \begin{Def}
        Комплексными корнями степени $n$ из единицы называются
решения уравнения $x^n = 1$.
    \end{Def}
    \begin{corollary}
        По основной теореме алгебры таких корней $n$
    \end{corollary}
    \begin{prop}
        Комплексными корнями степени $n$ из единицы равны $\omega^k_n=e^{\frac{2i\pi k}{n}}$
    \end{prop}
    Рассмотрим задачу интерполяции, если известны значения
многочлена
\[
P(x) = a_0 + a_1 x + \dots + a_{n-1} x^{\,n-1}
\]
в комплексных корнях из единицы степени \(n\),
\[
\omega_n^k, \quad k = 0, 1, \dots, n-1.
\]

Рассмотрим матрицу \(W\), которая будет фигурировать
в матричном решении задачи интерполяции:
\[
W =
\begin{pmatrix}
\omega_n^{0\cdot 0} & \omega_n^{0\cdot 1} & \dots & \omega_n^{0\cdot (n-1)} \\
\omega_n^{1\cdot 0} & \omega_n^{1\cdot 1} & \dots & \omega_n^{1\cdot (n-1)} \\
\vdots & \vdots & \ddots & \vdots \\
\omega_n^{(n-1)\cdot 0} & \omega_n^{(n-1)\cdot 1} & \dots & \omega_n^{(n-1)\cdot (n-1)}
\end{pmatrix}.
\]
    \begin{prop}
        $W^{-1}= \frac 1n V$, где $V=(\omega^{-ij})_{i,j=0}^{n-1}$
    \end{prop}
    \begin{proof}
        Посчитаем напрямую элементы матрицы \(WV\) и убедимся,
что утверждение верно:
\[
(WV)_{ij}
=
\sum_{k=0}^{n-1} W_{ik} V_{kj}
=
\sum_{k=0}^{n-1} \omega^{k(i-j)}.
\]

Это геометрическая прогрессия, поэтому
\[
\sum_{k=0}^{n-1} \omega^{k(i-j)}
=
\begin{cases}
\displaystyle
\sum_{k=0}^{n-1} \omega^{0}
= n, & i = j, \\[1.2ex]
\displaystyle
\frac{1-\omega^{n(i-j)}}{1-\omega^{i-j}}
= \frac{1-1}{1-\omega^{i-j}}
= 0, & i \neq j.
\end{cases}
\]

Следовательно,
\[
WV = n I_n.
\]

    \end{proof}
    \section{Дискретное преобразование Фурье. Быстрое преобразование Фурье. Преобразование бабочки.}
    \begin{Def}
        Пусть задан многочлен
\[
P(x) = a_0 + a_1 x + \dots + a_n x^{\,n}.
\]
Тогда \emph{дискретным преобразованием Фурье} называется вектор
\[
\operatorname{DFT}(P)
=
\bigl(
P(\omega_0),
P(\omega_1),
\dots,
P(\omega_{n-1})
\bigr)^{T},
\]
где \(\omega_k = \omega_n^{\,k}\), а \(\omega_n\) - примитивный корень
из единицы степени \(n\).
    \end{Def}
    Заметим, что преобразование Фурье можно записать в матричном
виде как $Wa = y$, где $a$ - вектор коэффициентов, а $y$ - вектор,
равный $\operatorname{FFT}(P)$. \\
Таким образом, надо быстро научиться умножать матрицу на вектор.
Рассмотрим три многочлена
\[
P(x) = a_0 + a_1 x + \dots + a_{n-1} x^{\,n-1},
\]
\[
P_0(x) = a_0 + a_2 x + a_4 x^{\,2} + \dots,
\]
\[
P_1(x) = a_1 + a_3 x + a_5 x^{\,2} + \dots .
\]

Заметим, что
\[
P(x) = P_0(x^{2}) + x\,P_1(x^{2}).
\]

Следовательно, для вычисления значений \(P(x)\) в корнях из единицы
достаточно вычислить значения многочленов \(P_0\) и \(P_1\) в \(n/2\) точках
\[
\omega_0, \omega_2, \dots, \omega_{2(n-1)},
\]
поскольку степени многочленов \(P_0\) и \(P_1\) в два раза меньше степени
многочлена \(P\).
\subsection*{Преобразование бабочки.}
Мы получили стандартную процедуру по схеме «разделяй и властвуй».
Осталось выразить \(\operatorname{DFT}(P)\) через \(\operatorname{DFT}(P_0)\) и \(\operatorname{DFT}(P_1)\).

Пусть
\[
\operatorname{DFT}(P_0) = (b_0, \dots, b_{n/2-1}), \quad
\operatorname{DFT}(P_1) = (c_0, \dots, c_{n/2-1}).
\]

Первые \(n/2\) значений вычисляются по формуле:
\[
\operatorname{DFT}(P)_k = b_k + \omega_n^k c_k, \quad k=0,\dots,n/2-1.
\]

Теперь разберём вторую половину:
\[
\begin{aligned}
\operatorname{DFT}(P)_{n/2+k} 
&= P(\omega_n^{\,n/2+k}) \\
&= P_0\bigl((\omega_n^{\,n/2+k})^2\bigr) + \omega_n^{\,n/2+k} P_1\bigl((\omega_n^{\,n/2+k})^2\bigr) \\
&= P_0(\omega_n^{\,2k}) + \omega_n^{\,n/2} \omega_n^k P_1(\omega_n^{\,2k}) \\
&= b_k + \omega_n^{\,n/2} \omega_n^k c_k \\
&= b_k - \omega_n^k c_k,
\end{aligned}
\]
так как \(\omega_n^{\,n/2} = -1\).

Таким образом, получили преобразование бабочки:
\[
\operatorname{DFT}(P)_k =
\begin{cases}
b_k + \omega_n^k c_k, & 0 \le k < n/2,\\[1ex]
b_{k-n/2} - \omega_n^{k-n/2} c_{k-n/2}, & n/2 \le k < n.
\end{cases}
\]
    \subsection*{Быстрое преобразование Фурье.}
    \begin{enumerate}
        \item Дополним многочлен $P$ нулевыми коэффициентами так, чтобы
        его степень была равна степени двойки.
        \item Разбиваем вычисление $DFT(P)$ на рекурсивное вычисление
        $DFT(P_0), DFT(P_1)$.
        \item Восстанавливаем ответ с помощью преобразования бабочки.
    \end{enumerate}
    Время работы определяется рекуррентой $T(n) = 2T(n/2) + O(n)$,
откуда время вычисления DFT(P) составит $O(n \log n)$, где $n = \deg P$.

    \section{Обратное преобразование Фурье. Перемножение многочленов.}
    \subsection*{Обратное преобразование.}
    Вспомним, что
    \[
    \operatorname{DFT}(P) = W a,
    \]
    где \(a\) - вектор коэффициентов, а
    \[
    W = (\omega^{ij})_{i,j=0}^{\,n-1}.
    \]
    
    С помощью FFT умеем это делать за \(O(n \log n)\).
    
    В матричной постановке обратное преобразование имеет вид
    \[
    W^{-1} \cdot \operatorname{DFT}(P),
    \]
    а уже доказано, что
    \[
    W^{-1} = \frac{1}{n} V, \quad V = (\omega^{-ij})_{i,j=0}^{\,n-1}.
    \]
    
    То есть нужно проделать всё то же самое, только заменить \(\omega\) на \(\omega^{-1}\),  
    и не забыть поделить на \(n\) в конце.

    \subsection*{Перемножение матриц.}
    \begin{enumerate}
        \item Считаем FFT(A) и FFT(B).
        \item Посчитаем $C(\omega^k)=A(\omega^k)\cdot B(\omega^k)$
        \item Вычислим обратное преобразование Фурье, то есть по DFT(C)
        найдем C.
    \end{enumerate}
    $O((n+m)\log (m+n))$

    \section{Свертка последовательностей. Расстояние Хэмминга. Алгоритм поиска вхождений паттерна в
    текст $с$ не более $k$ расхождениями.}
    
    \begin{Def}
        Пусть даны две последовательности
        \[
        a = [a_0, \dots, a_{n-1}], \quad
        b = [b_0, \dots, b_{m-1}], \quad n \ge m.
        \]
        
        Назовём \emph{свёрткой} \(a * b = c\) последовательность
        \[
        c = [c_0, \dots, c_{\,n-m+1}],
        \]
        где
        \[
        (a * b)_i = c_i = \sum_{k=0}^{m-1} a_{i+k} \, b_k.
        \]        
    \end{Def}
    \begin{note}
        Перед нами скалярное произведение вектора $b$ и всех
подотрезков $a$ как со скользящим окном.
    \end{note}
    Рассмотрим многочлены
\[
A(x) = a_0 + a_1 x + \dots + a_{n-1} x^{\,n-1}, \quad
B(x) = b_0 + b_1 x + \dots + b_{m-1} x^{\,m-1}.
\]

Обозначим их произведение за
\[
C(x) = A(x) B(x) = C_0 + C_1 x + \dots + C_l x^l.
\]

Рассмотрим, как устроены коэффициенты \(C\):

\[
\begin{aligned}
C_0 &= a_0 b_0, \\
C_1 &= a_0 b_1 + a_1 b_0, \\
&\vdots \\
C_{m-1} &= a_0 b_{m-1} + a_1 b_{m-2} + \dots + a_{m-2} b_1 + a_{m-1} b_0, \\
C_m &= a_1 b_{m-1} + a_2 b_{m-2} + \dots + a_{m-1} b_1 + a_m b_0, \\
&\vdots
\end{aligned}
\]

То есть \(C_{m-1+k}\) почти совпадает с \(c_k\), но $C_{m-1+k} = (a * b_R)_k$
То есть для вычисления свертки разворачиваем $b$, перемножаем
многочлены и берем нужные коэффициенты.
\begin{Def}
    Расстоянием Хэмминга для двух строк равной длины называют
величину $\rho_H (S, T)=\sum_{i=0}^{|S|-1} I(S_i \ne T_i)$.
\end{Def}
\begin{problem}
    Необходимо в тексте $T$ найти все вхождения паттерна $P$ с точностью
до $k$ символов. То есть найти все подстроки $S$ в $T$ такие, что
$\rho_H(S, P) \leqslant k$.
\end{problem}
\subsection*{Алгоритм.}
\begin{enumerate}
    \item Для каждого $\sigma \in \Sigma$ построем вектор $v_P^\sigma$, где $(v_P^\sigma)_i=I(P_i=\sigma)$. Аналогично потсроем $v_T^\sigma$.
    \item Подсчитаем $u_\sigma = v_\sigma^T * v_\sigma^P$ для каждого $\sigma \in \Sigma$. Заметим, что $u_i ^\sigma$
    соответствует числу таких позиций, что ровно в $u_i ^\sigma$
    позиций строки $T[i : i + |P|]$ и $P$ совпадают по букве $\sigma$.
    \item Подсчитаем $w = \sum_{\sigma \in \Sigma} u^\sigma$. $w_i$ говорит о том, в скольких позициях
    совпадают $T[i : i + |P|]$ и $P$.
    \item Если $w_i \geqslant |P|-k$, то позиция считается валидной.
\end{enumerate}
Сложность алгоритма: \\
$O(|\Sigma|(|P| + |T|) \log(|P| + |T|)) = O(|\Sigma||T| \log |T|)$.

    \section{Персистентные структуры данных. Частичная и полная персистентность. Персистентный стек.}

    \begin{Def}
        Для структуры $S$ назовем ее персистентной версией такую
структуру $pers(S)$, что ее интерфейс совпадает с интерфейсом $S$ и
имеется операция Access($k$) - возможность обращаться к версии на
момент $k$-го запроса изменения.
    \end{Def}
    \begin{Def}
        Структура частично персистентная, если результат Access(k)
дает read-only структуру.
    \end{Def}
    \begin{Def}
        Структура полностью персистентная, если результат Access(k)
дает доступ на изменение. Изменение применяется не только к версии,
но и ко всем ее потомкам!
    \end{Def}
    \begin{note}
        Как можно заметить, частично персистентные структуры имеют
граф версий в виде бамбука, тогда как полностью персистентные -
дерево версий.
    \end{note}
    \subsection*{Персистентный стек.}
    Храним стек ввиде дерева. Двигаем указатель. Ничего не удаляем.
    \begin{enumerate}
        \item pop() просто сдвигает указатель назад
        \item push() просто порождает очередного ребенка в дереве версий
    \end{enumerate}

    \section{Персистентные структуры данных. Частичная и полная персистентность. Персистентный массив}
    См. предыдущий пункт.
    \subsection*{Персистентный массив.}
    Строим ДО. Каждая версия - новый корень. Копируем только измененную ветку, на оставшиеся - ссылаемся.

    \section{Процедура \texttt{Merge}. Оптимальное время работы: оценка.}
    Пусть нам надо получить лишь позиции элементов, куда надо
вставлять элементы второго массива в первый. \\
И пусть $N >> M$, тогда нет смысла в классическом алгоритме, так как
выгоднее сделать $M$ бинпоисков за $O(\log N)$ времени каждый. \\

    \subsection*{Нижняя оценка \texttt{Merge}}
    Построем решающее дерево $(A[i]<?B[j])$. Листьев - $C_{N+M}^M$, глубина - $\log C_{N+M}^M$.
    \begin{theorem}[Формула Стирлинга - б/д]
        $N!\sim \sqrt{2\pi N} \left(\frac Ne\right)^N$
    \end{theorem}
    \begin{theorem}[Нижняя оценка \texttt{Merge}]
        Слияние двух массивов длины $N$ и $M$, где $N > 2M$, работает за $\Omega(N\log \frac MN)$ времени.
    \end{theorem}
    \begin{proof}
        \[
\log_2 \binom{M+N}{M}
\sim
\log_2
\frac{
\sqrt{2\pi (M+N)} \left(\dfrac{M+N}{e}\right)^{M+N}
}{
\sqrt{2\pi N} \left(\dfrac{N}{e}\right)^N
\cdot
\sqrt{2\pi M} \left(\dfrac{M}{e}\right)^M
}
\]

\[
=
\frac{1}{2}\log_2 \frac{M+N}{2\pi MN}
+ \log_2 \frac{(M+N)^{M+N}}{M^M N^N}
\]

\[
=
\frac{1}{2}\log_2 \frac{M+N}{2\pi MN}
+ \log_2\left(\frac{M+N}{M}\right)^M
+ \log_2\left(\frac{M+N}{N}\right)^N
\]

\[
=
\frac{1}{2}\log_2 \frac{M+N}{2\pi MN}
+ \log_2\left(1+\frac{N}{M}\right)^M
+ \log_2\left(1+\frac{M}{N}\right)^N
\]

\[
=
\frac{1}{2}\log_2 \frac{M+N}{2\pi MN}
+ M \log_2\left(1+\frac{N}{M}\right)
+ N \log_2\left(1+\frac{M}{N}\right).
\]
\[
\log_2 \binom{M+N}{M}
\sim
\frac{1}{2}\log_2 \frac{M+N}{2\pi MN}
+ M \log_2\left(1+\frac{N}{M}\right)
+ N \log_2\left(1+\frac{M}{N}\right).
\]

Будем считать, что \(N > 2M\). Тогда
\[
M \log_2\left(1+\frac{N}{M}\right) = \Theta(M),
\]
при этом первое слагаемое стремится к нулю при росте \(N, M\).

\[
\log_2 \binom{M+N}{M}
\sim
\frac{1}{2}\log_2 \frac{M+N}{2\pi MN}
+ M \log_2\left(1+\frac{N}{M}\right)
+ N \log_2\left(1+\frac{M}{N}\right)
\]

\[
= \Theta(M) + N \log_2\left(1+\frac{M}{N}\right)
= \Omega(N) + N \log_2\left(1+\frac{M}{N}\right)
= \Omega\!\left(N \log \frac{M}{N}\right).
\]

    \end{proof}


    \section{Процедура \texttt{Merge}. Оптимальное время работы: оценка б/д, алгоритм.}
    См. предыдущий пункт. \\
    \subsection*{Galloping search.}
    Пусть $k$ - позиция куда попадает ответ, а $p=0$ - номер итерации. 
    \begin{enumerate}
        \item Заведем указатель на нулевой элемент массива, сравним с
        искомым. Если все ок, то победа, иначе идем дальше.
        \item Сдвинем указатель на $2^p$. Если уже перескочили, то достаточно
        запустить обычный бинарный поиск на отрезке $[0, 2^p]$, иначе
        повтори этот шаг, увеличив номер итерации на единичку.
    \end{enumerate}
    Время работы: $O(\log k)$. \\
    Выше алгоритм, который вырождается в бинпоиск в одном
экстремальном случае и в константу в другом. \\
Будем искать место вставки не бинарным, а галлопирующим поиском.
Пусть $k_i$ - место, куда вставили $a[i]$, тогда можно оценить время
работы алгоритма следующим образом:
\[
O\!\left(\sum_{i=1}^{M} \log k_i \right)
=
O\!\left(
M \cdot \frac{1}{M}\sum_{i=1}^{M} \log k_i
\right)
\]

\[
=
O\!\left(
M \log\!\left(
\frac{1}{M}\sum_{i=1}^{M} k_i
\right)
\right)
=
O\!\left(
M \log \frac{N}{M}
\right).
\]

    \section{\texttt{Inplace Merge Sort}.}
    
    Хотим $O(1)$ доппамяти. 
    \begin{enumerate}
        \item Сортируем правую половину, используя в качестве буффера
        левую - получаем массив $C$.
        \item Сортируем первую четверть, используя в качестве буффера
        вторую четверть - получаем массив $A$.
        \item Сливаем, чтобы элементы не перезатирались - получаем массив $C$ длины $\frac{3N}{4}$:
        \begin{itemize}
            \item Начинаем выписывать ответ со второй четверти
            \item Пользуемся только swap, никаких присваиваний
        \end{itemize}
        \item Повторять шаги 2-3 до победного, только беря не четверти, а
        восьмые, шестнадцатые, etc.
        \item Последний один элемент вставим за линейное время.
    \end{enumerate}

    В алгоритме есть шаги двух видов: слияния и сортировки. Всего
шагов $\log_2 N$.
\begin{itemize}
    \item Слияние. Каждое работает за $O(N)$, их всего $\log_2$ штук, то есть $O(N\log N)$ времени.
    \item Сортировка. Сортируем массивы размерами $\frac{N}{2^k}, k\in \overline{1, \log_2 N}$.
\end{itemize}
    
    \section{Алгоритм \texttt{Introsort}.}
    \begin{enumerate}
        \item Задаем два параметра: max\_depth как функцию от $N$ и
        min\_length.
        \item Если длина массива меньше min\_length, то квадратичная
        сортировка (обычно сортировка вставками).
        \item Если глубина рекурсии больше max\_depth(N), то запускаем
        HeapSort.
        \item Иначе выбираем как-то быстро опорный элемент pivot (например,
        медиана из первого, последнего и серединного элементов). Далее
        Partition и рекурсивно левую и правую части сортируем.
    \end{enumerate}
    
    \section{Биномиальные деревья. Свойства: число вершин на уровне. Процедуры \texttt{SiftDown}, \texttt{SiftUp} и
    \texttt{DecreaseKey} в биномиальном дереве.}
    \begin{Def}
        Биномиальное дерево ранга $k$ $T_k$ - корневое дерево следующего вида:
        \begin{itemize}
            \item Если $k = 0$, то это один корневой элемент
            \item Если $k > 0$, то это дерево $T_{k-1}$, подвешенное к такому же по
            структуре $T_{k-1}$.
        \end{itemize}
    \end{Def}
    В биномиальном дереве выполняется свойство кучи. \\
    Свойства биномиального дерева:
    \begin{enumerate}
        \item В $T_k \ 2^k$ элементов.
        \item В $T_k$ на $i$ $C_k^i$ элементов. $C_k^i=C_{k-1}^i+C_{k-1}^{i-1}$
    \end{enumerate}

    \subsection*{\texttt{SiftDown}.}
    \begin{enumerate}
        \item Выбираем с ребенка минимальным значением.
        \item Если соотношение верно - останавливаемся.
        \item Иначе - меняемся с корнем и рекурсивно запускаемся.
    \end{enumerate}
    \subsection*{\texttt{SiftUp}.}
    Аналогично, пока вершина не корень - талкаем наверх.
    \subsection*{\texttt{DecreaseKey}.}
    Надо уменьшить элемент - уменьшаем и \texttt{SiftUp}.

    \section{Биномиальная куча. Время работы слияния куч. Выполнение основных операций кучи.}
    \begin{Def}
        Биномиальная куча - набор биномиальных деревьев попарно различных рангов с указателем на минимальный из корней.
    \end{Def}
    \subsection*{Поиск минимума.}
    \begin{itemize}
        \item Для поиска минимума достаточно найти наименьший корень.
        \item Функция будет работать за $O(1)$.
    \end{itemize}
    \subsection*{Слияние.}
    Даны две кучи размера $N$ и $M$. Рассмотрим каждое из чисел в виде
его двоичной записи. \\
Будем эмулировать сложение этих двоичных чисел начиная с
младшего разряда. \\
При переносе разряда выполняется слияние двух деревьев одного
ранга. А именно, $T_k$ с большим корнем подвешивается к корню $T_k$ с
меньшим. Таким образом, получаем $T_{k+1}$ или ту самую «единичку в
уме». \\
Заметим, что все это выполняется за $O(log(N + M))$ времени.
    \subsection*{Вставка.}
    \begin{itemize}
        \item Создаем кучу из одного биномиального дерева.
        \item Эту кучу можно слить с исходной.
        \item Работать это будет за $O(\log n)$.
    \end{itemize}
    \subsection*{Извлечение минимума.}
    \begin{itemize}
        \item Ищем min корень в списке корней.
        \item Заметим что его дети – это тоже биномиальные деревья.
        \item Нужно перевернуть список детей, и это будет биномиальной
        кучей.
        \item Сольем две кучи.
    \end{itemize}
    Время: $O(\log n)$.

    \section{Фибоначчиева куча. Топология узла. Структура кучи. Операции \texttt{Insert}, \texttt{Merge}, \texttt{GetMin}.}
    \begin{Def}
        Фибоначчиева куча позволяет делать следуюшие операции:
        \begin{enumerate}
            \item GetMin за $O(1)$
            \item Merge за $O(1)$
            \item DecreaseKey за $O^*(1)$
            \item ExtractMin за $O^*(\log n)$
            \item Insert за $O(1)$
        \end{enumerate}
    \end{Def}
    \subsection*{Топология.}
    Узел фибоначчиевой кучи состоит из элемента и двусвязного списка
детей, на концы которого лежат указатели в узле. Также храним
указатель на предка. \\
Если вершина не корневая, то в узле лежит еще указатели на соседние
элементы в списке детей родительского узла (братья). \\
Фибоначчиева куча - двусвязный список почти биномиальных
деревьев с поддержкой указателя на минимальный корень.
    \begin{lstlisting}
struct Node {
    T value;
    Node* parent;
    Node* left_brother;
    Node* right_brother;
    Node* children_start;
    Node* children_end;
    int rank; // number of children
    bool mark; // was one of children erased
};
    \end{lstlisting}
    \subsection*{Удаление поддерева.}
    Вынесем вершину и все ее поддерево в конец списка корней. То есть
удалим узел из списка детей родительской вершины и свяжем братьев
друг с другом.
    \subsection*{\texttt{Insert}.}
    Для вставки достаточно вставить в список корней новое дерево из
одного элемента. Еще надо обновить указатель на минимум.
    \subsection*{\texttt{GetMin}.}
    Храним указатель.
    \subsection*{\texttt{Merge}.}
    Нужно сконкатенировать списки корней.

    \section{Фибоначчиева куча. Структура кучи. Операции \texttt{Consolidate}, \texttt{ExtractMin}. Оценка на $D(n)$}
    
    См. предыдущий пункт.
    \subsection*{\texttt{Consolidate}.}
    Операция \texttt{Consolidate} нужна для того, чтобы сделать из списка
элементов фибоначчиеву кучу. \\
Ранг дерева в фибоначчиевой куче - ранг (степень) корня. Запускаем
процедуру аналогичную Merge в биномиальной куче: сливаем два
дерева в одно рангом на 1 побольше. \\
Пусть $D(n)$ - максимально возможный ранг в куче на $n$ элементах. 
    \begin{enumerate}
        \item Заведем массив $C$ размера $D(n)$, где $C[i]$ - указатель на корень
        дерева ранга $i$.
        \item Пробегаемся по списку деревьев в куче и, если дерева такого
        ранга еще нет, то добавляем в массив указатель. Иначе сливаем
        деревья, пока нужно.
        \item Еще поддерживаем указатель на минимальный корень.
    \end{enumerate}
    Время работы: $O(D(n) + k)$, где $k$ - число деревьев в куче. Число
объединений $\leqslant k - 1$. \\
Отныне ранги всех корней различны.
    \subsection*{Mark.}
    \begin{enumerate}
        \item У корня всегда mark = false. Не важно, сколько детей у него
        вырезали.
        \item Ставится в true, когда вершина - не корень, а у нее вырезается
        один из детей.
    \end{enumerate}
    \subsection*{\texttt{ExtractMin}.}
    \begin{enumerate}
        \item Получаем узел.
        \item Удаляем вершину, а всех ее детей добавим в список корней (как в
        биномиальной куче). 
        \item У всех детей зануляем родителя, то есть $O(rank)$. 
        \item Обновляем указатель на минимум.
        \item Вызываем \texttt{Consolidate}.
    \end{enumerate}
    \subsection*{\text{DecreaseKey}.}
    Дан указатель на элемент, значение в котором надо уменьшить (куча
на минимум). Значит может нарушиться неравенство с родительским
узлом.
    \begin{enumerate}
        \item Вырезаем элемент, чье значение надо уменьшить, с поддеревом.
        \item Меняем значение в новом корне, сбрасываем mark. Пересчитываем минимум.
        \item Помечаем parent.mark = true. parent.rank -= 1.
        \item Если у parent уже был mark = true, вырежем поддерево
        родителя в список корней и шаги 2-4 уже для него!
    \end{enumerate}
    \subsection*{Время \texttt{Consolidate}.}
    На каждом корне лежит по монете, а на вершине с mark = true по
две монеты. \\
Тогда на каждое слияние в рамках Consolidate уйдет по монете и на
новом корне монета останется. \\
Так что слагаемое $k$ в $O(D(n) + k)$ «нивелируется»: монеты лишние
не истрачены. Значит время Consolidate: $O^*(D(n))$.
    \subsection*{Время \texttt{DecreaseKey}.}
    На каждом корне лежит по монете, а на вершине с mark = true по
    две монеты. \\
    Тогда на вырезание первой вершины уходит $O(1)$ действий - одна
    монета, еще одна монета останется на новом корне. \\
    Когда закончим подъем, на последнюю вершину с mark = false
    кладем две монеты. \\
    Итого: $O(1)$ действий + 2 монеты, откуда выходит время работы: $O^*(1)$.
    \subsection*{Оценка на $D(n)$.}
    $D(n)$ - максимальный ранг корня дерева на n вершинах. Решим
обратную задачу: пусть максимальный ранг равен $k$, найдем $S(k)$ -
минимальное число вершин в дереве ранга $k$. \\
$S(0) = 1, S(1) = 2$. Пусть у вершины $v$ ранг равен $k$, значит у нее $k$
детей $u_0, \dots , u_{k-1}, u_i$ упорядочены по времени подвешивания к $v$.
    \begin{prop}
        Ранг $u_i$ хотя бы $i - 1$.
    \end{prop}
    \begin{proof}
        В момент подвешивания $u_i$ ранг $v$ был хотя бы $i$, так как сливаем
деревья одинакового ранга. А уменьшить ранг (вырезать дочерний
узел) можно не больше чем один раз.
    \end{proof}
    У детей массив рангов не меньше чем $[0, 0, 1, 2, \dots , k - 2]$. Значит
    \[S(k)\geqslant 2+\sum_{i=0}^{k-2} S(i)\]
    \begin{lemma}
        $S(k)\geqslant F_{k}$
    \end{lemma}
    \begin{prop}
        \[F_n=1+\sum_{i=0}^{k-2} F_i\]
        Док-во по индукции.
        \[S(k)\geqslant 2+\sum_{i=0}^{k-2} S(i) \geqslant 1+\sum_{i=0}^{k-2} F_i\geqslant F_k\]
    \end{prop}

    \section{Фибоначчиева куча. Структура кучи. Операции \texttt{Consolidate}, \texttt{DecreaseKey}. Оценка на $D(n)$.}
    См. предыдущий пункт.

    \section{Алгоритмы во внешней памяти. Устройство памяти и понятие I/O-операции. Понятия latency,
    throughput. Модель оценивания времени на основе I/O-операций. Модельная задача: сумма
    последовательности во внешней памяти.}
    Имеются три устройства: CPU, RAM и EM (External memory, диск) -
    HDD или SSD. \\
    Объем RAM $M$ порядка 100 гигов в мощных вычислителях, тогда как
дисков $N$ порядка 10 Тб. \\
В RAM-модели за одну операцию можно было считать одно машинное
слово длины $w \in \{32, 64\}$ (длина регистра).
    \subsection*{Модель диска.}
    \begin{enumerate}
        \item Можно считать, что дисковая память - непрерывная лента, хотя
        это не так
        \item  Нет понятия машинного слова, так как чтение происходит не в
        регистры
        \item Лента поделена на блоки размера $B >> w$
        \item За одну операцию можно прочитать/записать один выровненный
        блок (I/O операция)
    \end{enumerate}
    \begin{Def}
        I/O-операция (Input/Output) - это передача блока данных между RAM и EM.
    \end{Def}
    \begin{Def}
        Latency (задержка) - время между запросом и началом передачи данных.
    \end{Def}
    \begin{Def}
        Throughput (пропускная способность) - скорость самой передачи данных.
    \end{Def}
    Пусть $N$ - размер входных данных, $M$ - размер оперативной памяти, $B$ - размер блока.
    \subsection*{Сложность.}
    \begin{enumerate}
        \item I/O операция объявляется элементарной
        \item Сложность алгоритма - число I/O операций
        \item Действия CPU с RAM не учитываются
    \end{enumerate}
    \subsection*{Размер блока.}
    В силу устройства диска, I/O-операции состоят из трёх стадий:
\begin{enumerate}
\item вращение диска, скорость порядка \(10^4\) оборотов в минуту;
\item позиционирование головки;
\item собственно I/O-операция.
\end{enumerate}

Первые два пункта занимают порядка \(10\,\text{ms}\), а значит итоговое время
работы равно
$
10\,\text{ms} + \frac{x}{\text{throughput}},
$
где \(x\) - объём I/O-операции.

Однако в модели время работы равно
$
\frac{x}{B}$.
Проблема в том, что здесь отсутствует аддитивное слагаемое, которое существенно
влияет при малых объёмах данных.

Решение: запретить маленькие I/O-операции, так чтобы
$
\frac{x}{\text{throughput}} \ge 10\,\text{ms}.
$

Тогда
$
B \ge 1\,\text{Mb},
$
а на практике лучше брать порядка \(10\,\text{Mb}\).
\subsection*{Сумма элементов.}
Читаем блоками, суммируем. $O(\frac NB)$.
    
    \section{Алгоритмы во внешней памяти. Модель оценивания времени на основе I/O-операций. Сортировка во внешней памяти.}

    \subsection*{MergeSort.}
    Отличия:
    \begin{enumerate}
        \item В листьях висят блоки. Их сортируем во внутренней памяти.
        \item Один уровень работает за $Scan(N)=\frac NB$
    \end{enumerate}
    Сложность $\frac NB \log_2 \frac NB$.
    \subsection*{Улучшение 1.}
    Давайте ограничим дерево не блоками по $B$, а величинами порядка $M$.
Уже сложность $\frac{N}{B} \log_2 \frac NM$.
    \subsection*{Улучшение 2.}
    Сливаем не по два, а по $K$ массивов. Глубина $\log_K \frac{N}{M}$
    \subsection*{Улучшение 3.}
    $K=\frac{M}{B}$

    \begin{theorem}
        Сортировка во внешней памяти работает за $\Omega (\frac{N}{B} \log_{\frac{M}{B}} \frac NM)$.
    \end{theorem}

    \section{$(a, b)$-дерево. Операции \texttt{SplitNode}, \texttt{Fuse}, \texttt{Share}.}
    \begin{Def}
        $(a, b)$-дерево, где $a\geqslant 2, b \geqslant 2a-1$ - дерево поиска, которое удовлетворяет следующим требованиям:
        \begin{enumerate}
            \item У корня либо $[2; b]$ детей, либо 0.
            \item У остальных элементов количество детей $[a; b]$ и число элементов в ноде $\in [a -1; b -1]$.
            \item Ключи в ноде упорядочены.
            \item Все листья находятся на одной глубине.
        \end{enumerate}
    \end{Def}
    \begin{lemma}
        $h=O(\log_a n), h=\Omega(\log_b n)$
    \end{lemma}
    \begin{proof}
        Скипнем первый уровень. Пусть на втором уровне $k$ вершин. Тогда число элементов в дереве
        \[n\geqslant \sum_{t=0}^{h} a^t k=\frac{k(1-a^{h+1})}{1-a}\sim ka^h \Rightarrow h=O(\log_a n)\]
    \end{proof}
    \subsection*{\texttt{SplitNode} (расщипление).}
    Используется при переполнении узла (когда ключей стало $b$) - обычно при вставке.
    \begin{enumerate}
        \item Выбрать медиану.
        \item Узел делится на левый и правый.
        \item Медиана - в родителя.
        \item Если родитель переполнен - рекурсивно вызываемся от него.
    \end{enumerate}
    \subsection*{\texttt{Fuse} (слияние).}
    Используется при недостатке ключей (меньше $a-1$) - обычно при удалении.
    \begin{enumerate}
        \item Берётся узел, его сосед (левый или правый) и разделяющий ключ родителя.
        \item Все ключи объединяются в один узел.
        \item Разделяющий ключ удаляется из родителя.
        \item Если у родителя стало слишком мало ключей - операция продолжается вверх.
    \end{enumerate}
    \subsection*{\texttt{Share} (перераспределение).}
    Операция балансировки, применяемая при удалении, когда в узле стало меньше $a-1$ ключей, но соседний брат имеет больше минимума. \\
    Расмотрим с правым братом:
    \begin{enumerate}
        \item Разделяющий (с правым братом) ключ опускается в текущую вершину.
        \item Минимальный ключ из правого брата поднимается в родителя.
        \item Вершины переносятся из правого брата в текущую.
    \end{enumerate}
    \subsection*{Поиск.}
    Спускаемся по дереву, выбираем нужного сына, бинпоиск.

    \subsection*{Вставка.}
    \begin{enumerate}
        \item Находим лист.
        \item Вставляем ключ.
        \item При переполнении - SplitNode.
    \end{enumerate}
    \subsection*{Удаление.}
    \begin{enumerate}
        \item Находим ключ.
        \item Удаляем.
        \item Пытаемся Share (длина узла $\geqslant a$), иначе - Fuse.
    \end{enumerate}

    \section{Алгоритмы во внешней памяти. Модель оценивания времени на основе I/O-операций. $(a, b)$-
    дерево. Основные операции с $(a, b)$-деревом.}
    См. предыдущий пункт.

    \section{Алгоритмы во внешней памяти. Модель оценивания времени на основе I/O-операций. BufferTree
    как $(a, b)$-дерево. Разбиение буффера на две части: основную и накопительную с родителей.}
    См. предыдущий пункт.
    \begin{Def}
        Beffer Tree - это $\left(\frac MB, \frac{4M}{B}\right)$-дерево, в каждом листе которого есть блок
        из $B$ ключей. К тому же, в каждой нелистовой ноде есть буфер на $X\leqslant M$ элементов.
    \end{Def}
    \begin{itemize}
        \item Пока можем, буферизуем в памяти.
        \item Потом скидываем в буфер корня.
        \item Переполнили буфер - вызываем Flush:
        \begin{enumerate}
            \item Считываем буфер в RAM.
            \item Сортируем запросы в RAM
            \item Скидываем запросы в соответствующие поддеревья (Scatter).
        \end{enumerate}
    \end{itemize}
    Проблема: Может быть, нам придётся делать Flush рекурсивно.
    Решение: к каждому узлу добавляем накоп (буфер побольше и отсортированный).

    \section{Задание полуплоскости. Пересечение полуплоскостей за $O(N^2)$.}
    Будем задавать полуплоскость неравенством $ax + by + c \geqslant 0$ и хранить
как тройку $(a, b, c)$. \\
Тогда нормаль $(a, b)$ смотрит в часть плоскости, содержащую
полуплоскость.

    \subsection*{Пересечение полуплоскостей за $O(N^2)$.}
    \begin{enumerate}
        \item Изначально считаем, что результат - bounding box.
        \item Добавляем полуплоскости по одной:
        \begin{enumerate}
            \item Пересекаем полуплоскость с каждой стороной многоугольника и
            находим две точки $P_i, P_j$ за $O(N)$.
            \item Все точки в порядке обхода между $P_i$ и $P_j$ удаляем за $O(N)$.
        \end{enumerate}
    \end{enumerate}
    
    \section{Пересечение полуплоскостей за $O(N \log N )$ через построение огибающих.}
    \begin{enumerate}
        \item Разобьем полуплоскости на две группы по полярному углу $\phi$ нормали
        относительно оси $OX$: в первой группе $\phi \in [0, \pi)$, во второй:
        $\phi \in [\pi, 2\pi)$.
        \item Внутри каждого класса сортируем по возрастанию $\phi$. Если есть несколько паралельных прямых - оставляем одну с самым "сильным" неравенством.
        \item В каждой группе: добавляем в порядке сортировки.
        \item Пока пересечение не лежит в новой полуплоскости - удаляем последнюю.
        \item Получили верхную и нижную огибающую - пересека скайлайном слева направо.
    \end{enumerate}

    \section{Пересечение полуплоскостей за $O(N \log N )$ без построения огибающих.}
    Аналогично предыдущему, но используем дек.
    \begin{note}
        \begin{enumerate}
            \item Если нормали двух полуплоскостей сонаправлены, то надо взять ту
            полуплоскость, у которой наименьший коэффициент $c$ в уравнении
            $ax + by + c \geqslant 0$, единственное - надо не забыть сделать нормали
            единичными.
            \item В момент опустения (останется в деке одна полуплоскость) надо
            проверить, что поворот против часовой от нормали в деке до нормали
            новой прямой меньше $\pi$, иначе пересечение пусто.
        \end{enumerate}
    \end{note}

    \section{Диаграмма Вороного за $O(N^3)$ или за $O(N^2 log N)$.}
    \begin{Def}
        Пусть задан набор точек $P_1, \dots, P_n \in \RR^2$ (сайты). Тогда локусом $P_i$ назовем
        \[\{X\in \RR^2| \forall j\ne i \ |P_i-X|<|P_j-X|\}\]
        Или множество тех точек плоскости, которые ближе к заданной, чем к
остальным по евклидовой метрике.
    \end{Def}    
    \begin{Def}
        Диаграмма Вороного для заданного набора $P_1, \dots, P_n$ -
разбиение $\RR^2$ на локусы для заданного набора.
    \end{Def}
    \subsection*{Алгоритм за $O(N^2 log N)$.}
    Для каждой точки P построим свой локус:
    \begin{enumerate}
        \item Проведем отрезки $[P, P_i]$, построим к каждому из них серединные
        перпендикуляры и выберем ту полуплоскость, в которой лежит $P$.
        \item Пересекаем серперы.
    \end{enumerate}


    \section{Диаграмма Вороного. Линейность числа ребер и граней.}
    См. предыдущий пункт.
    \begin{prop}
        Пусть $P_1, \dots, P_n$ - сайты. Тогда
        \begin{enumerate}
            \item Если все сайты лежат на одной прямой, то диаграмма Вороного - $n-1$ паралельная прямая.
            \item Иначе, все ребра - либо отрезки или лучи и диаграмма связна.
        \end{enumerate}
    \end{prop}
    \begin{proof}
        Докажем, что ребра - либо отрезки или лучи.
        \begin{center}
            \includegraphics[width=0.8\textwidth]{voronogo1.png}
        \end{center}
        Докажем, что граф связен.
        \begin{center}
            \includegraphics[width=0.8\textwidth]{voronogo2.png}
        \end{center}
    \end{proof}
    \begin{prop}
        В графе $\leqslant 2n-5$ вершин и $\leqslant 3n-6$ ребер.
    \end{prop}
    \begin{prop}
        Формула Эйлера: $|V| - |E|+|\Gamma| = 2$. Возьмем достаточно большой
bounding box (bbox) и сузим диаграмму на него. Возьмем точку
$v_0$ на бесконечном удалении и соединим все полубесконечные
ребра с ней с сохранением планарности,верим, что можно? \\
Значит $|V| + 1 - |E| + N = 2$ или $|E| = |V| + N - 1$. \\
$\forall v \in V \deg(v) \geqslant 3$. Для внутренних очевидно. Теперь для v0.
Пусть было только два бесконечных луча. Значит есть
полуплоскость вне bbox не пересекающая эти лучи, то есть она
содержится целиком в грани. \\
Значит $2|E| \geqslant 3(|V| + 1)$. То есть $2|V| + 2N - 2 \geqslant 3|V| + 3$ или
$|V| \geqslant 2N - 5$, отсюда $|E| \geqslant 3N - 6$.
    \end{prop}

    \section{Диаграмма Вороного. Критерии того, что точка является вершиной или лежит на ребре в диаграмме Вороного.}
    \begin{Def}
        Пусть $\{P_1, \dots, P_N\}$ - набор точек и $Q\in \RR^2$, тогда $C(Q)$ -
        круг максимального радиуса с центром в $Q$, не содержащий внутри
        себя точек из $P$. 
    \end{Def}
    \begin{prop}
        \begin{enumerate}
            \item $Q$ - вершина диаграммы Вороного $\Leftrightarrow \ C(Q)$ содержит на границе хотя бы три точки.
            \item Кусок серпера $l_{ij}$ к $P_i P_j$ является ребром диаграммы $\Leftrightarrow \ \exists Q\in l_{ij}$ такая, что 
            $C(Q)$ содержит только $P_i, P_j$.
        \end{enumerate}
    \end{prop}
    \begin{prop}
        \begin{enumerate}
            \item $\Rightarrow$ Если $Q$ - вершина чьей-то грани, то ее степень хотя бы три, а
            значит она равноудалена от соответствующих точек. \\
            $Leftarrow$ Раз внутри $C(Q)$ никого нет, а на границе $P_i, P_j, P_k$, значит
            $Q\in V(P_i)\cap V(P_j)\cap V(P_k)$, а это только вершина.
            \item $\Rightarrow$ Пусть $l_{ij}$ содержит ребро, возьмем отрезок внутри ребра ненулевой
            длины и его середину $Q$. Построим круг с центром в $Q$, содержащий на границе $P_i, P_j$.
            Внутри никого нет, так как иначе $Q$ ближе к этой точке. \\
            $\Leftarrow$ Напрямую из условия следует, что $\forall k\ne i, j \ dist(P_i, Q)=dist(P_j, Q)< dist(Q, P_k)$.
            Тогда внутри $\frac{\varepsilon}{2}$ окрестности $Q$ вдоль $l_{ij}$ нет других точек.
        \end{enumerate}
    \end{prop}

    \section{Диаграмма Вороного. Алгоритм Форчуна.}

    Сканирующая прямая $\pi$ идет сверху вниз. Выше прямой диаграмма уже есть и по мере движения она эволюционирует. \\
Будем поддерживать диаграмму для тех точек, про которые уже все
известно. \\
Диаграмма известна для тех точек $X$, что ближе к какой-то другой точке $P_i$, чем к $\pi$.
Тогда граница области представляет из себя ГМТ равноудаленных от точки и прямой, а это парабола, где $P_i$ - фокус, а $\pi$ - директриса.
\begin{Def}
    Береговая линия (beach line) - набор дуг парабол с фокусами в
точках выше $\pi$, чья директриса $\pi$.
\end{Def}
Будем хранить ее как дерево поиска по абсциссе фокуса. \\
В рамках движения $\pi$ могут происходить события двух типов.
\begin{enumerate}
    \item $\pi$ достигла очередной точки диаграммы (событие точки, site
    event).
    \item По мере движения $\pi$ вниз какая-то из парабол схлопнулась между
    двух других (событие круга, circle event).
\end{enumerate}
    \subsection*{Обработка Site event.}
    \begin{enumerate}
        \item Вставить новую параболу в береговую линию.
        \item Посчитать для нее события круга с ее соседями.
    \end{enumerate}
    При этом точки пересечения парабол удовлетворяют второму свойству
границ и, следовательно, вычерчивают ребра диаграммы.
    \subsection*{Обработка Circle event.}
    В событии круга две параболы зажали третью, тем самым два ребра
пересеклись и породили третье. \\
Значит точка стала равноудалена от трех фокусов соседних парабол
То есть получаем новую вершину диаграммы Вороного. \\
Не забудем удалить схлопнутую параболу. \\
Так как вершина соответствует трем точкам $P_i, P_j, P_k$
(последовательных в beach line), она равноудалена от них и от
директрисы. \\
Найдем описанную около $P_i, P_j, P_k$ окружность, тогда circle event
появляется в момент прохождения $\pi$ самой нижней точки окружности. \\
Если $P_i, P_j, P_k$ на одной прямой, то параболы никогда не схлопнутся,
так как линия пересечения двигаются вдоль параллельных серперов.
    \subsection*{Алгоритм Форчуна.}
    \begin{enumerate}
        \item Сортируем точки по ординате и добавляем в кучу все site event.
        \item Поддерживаем в ходе движения сканирующей прямой береговую
        линию.
        \item Практически каждый (кроме случая одной прямой) новый site
        event порождает новый circle event, который добавляем в кучу.
        \item Site event - добавление новой параболы в beach line.
        \item Circle event - удаление параболы и добавление новых circle event
        для двух новых троек.
        \item Если Circle event «протух» (параболы уже схлопнулись), то
        игнорим (проверяем, что его параболы существуют и
        последовательные).
    \end{enumerate}
    \subsection*{Время работы.}
    \begin{enumerate}
        \item Сортировка site events: $O(N \log N)$
        \item Каждый site event порождает один circle event.
        \item Каждый circle event порождает еще два circle event однако их
        всего $O(N)$.
        \item Каждое событие обрабатывается за $O(\log N)$.
    \end{enumerate}
    Итоговое время работы $O(N \log N)$.

    \section{Граф Делоне. Линейность числа ребер и граней в графе Делоне. Критерии того, что вершина/ребро будут в графе Делоне.}
    \begin{Def}
        Пусть $S\subset \RR^2$, $|S| = N$, тогда триангуляция S - максимальная по
включению совокупность треугольников, вершины которых из S,
пересекающихся по общим ребрам или общим вершинам.
    \end{Def}
    \begin{Def}
        Пусть $S\subset \RR^2, |S| = N, Vor(S)$ - диаграмма Вороного, тогда граф Делоне:
        \begin{itemize}
            \item Вершины $V = S$
            \item Ребра $P_i, P_j$, если $V(P_i), V(P_j)$ - пересекаются по ребру положительной длинны.
        \end{itemize}
    \end{Def}
    \begin{prop}
        Пусть $|S| = N$ и $K$ - число вершин на границе выпуклой оболочки, тогда в любой
триангуляции $S$ $2N - K - 2$ треугольника и $3N - K - 3$ ребра.
    \end{prop}
    \begin{proof}
        $|V|=N, \Gamma=M+1$($M$ треугольников и 1 внешняя), $|E|=\frac{3M+K}{2}$ 
        Формула Эйлера: $N-\frac{3M+K}{2}+M+1=2 \Rightarrow M=2N-K-2$
    \end{proof}
    \begin{prop}
        \begin{enumerate}
            \item $P_i, P_j, P_k$ являются вершинами одной грани графа Делоне $\Leftrightarrow$
            $\exists Q$ такая, что $C(Q$) содержит их на границе. Более того, каждая
            грань графа Делоне - вписанный многоугольник
            \item В графе Делоне есть ребро $P_i P_j \Leftrightarrow$ на серпере к $P_i P_j$ такая, что $C(Q)$ содержит только $P_i, P_j$
        \end{enumerate}
    \end{prop}
    \begin{proof}
        См. аналогичное утверждение про диаграмму Вороного.
    \end{proof}

    \section{Независимость величины минимального угла от триангуляции граней графа Делоне. Два алгоритма построения: двояйственный к диаграмме Вороного и модификация алгоритма Форчуна.}
    \begin{Def}
        Триангуляция Делоне - произвольная триангуляция графа Делоне.
    \end{Def}
    \begin{note}
        Минимальный угол произвольно триангулированного вписанного многоугольника не зависит от триангуляции.
    \end{note}
    \subsection*{Алгоритм через диаграмму Вороного.}
    Пусть $S=\{P_1, \dots, P_N\}\subset \RR^2$.
    \begin{enumerate}
        \item Строим диаграмму Вороного Vor(S).
        \item Проводим ребро триангуляции $P_i P_j$, если кусок серпера к $P_i P_j$ участвует в диаграмме Вороного.
        \item Дотриангулируем не треугольные грани графа Делоне.
    \end{enumerate}
    Время: $O(N \log N)$.
    \subsection*{Форчун-based алгоритм.}
    \begin{enumerate}
        \item По мере алгоритма Форчуна если параболы с фокусами в $P_i, P_j$
        оказываются соседями в береговой линии, то проводим ребро
        графа Делоне.
        \item Дотриангулируем не треугольные грани графа Делоне.
    \end{enumerate}
    Время: $O(N \log N)$.

    \section{Легальное ребро. Критерий легальности ребра, триангуляции. Легальность триангуляции Делоне.}
    \begin{Def}
        Рассмотрим ребро и смежные ему две грани $\triangle ABD$ и $\triangle ACD$ в
триангуляции Делоне. Флип ребра - процедура замены диагонали $AD$
четырехугольника $ABCD$ на диагональ $BC$.
    \end{Def}
    \begin{Def}
        Ребро нелегально, если флип ребра приводит к увеличению
минимального угла.
    \end{Def}
    \begin{prop}
        Пусть $P_iP_jP_k, P_iP_jP_l$ - треугольники треангуляции. Ребро $P_iP_j$ легально $\Leftrightarrow$
        окружность, описанная вокруг $P_iP_jP_k$ не содержит $P_l$.
    \end{prop}
    \begin{proof}
        Рассмотрим дуги:
        \begin{center}
            \includegraphics[width=0.8\textwidth]{triangular1.png}
        \end{center}
    \end{proof}

    \begin{prop}
        Триангуляция легальна $\Leftrightarrow$ трианугляция является триангуляцией Делоне.
    \end{prop}
    \begin{proof}
        $\Leftarrow$ Предположим, что триангуляция легальна, но не является триангуляцией Делоне. \\
        Тогда существует треугольник, в описанной окружности которого лежит некоторая точка $P$. \\
        
        Рассмотрим путь от $P$ к этому треугольнику через соседние треугольники триангуляции. Можно показать, что на этом пути обязательно найдётся ребро, для которого противоположная вершина лежит внутри описанной окружности соседнего треугольника. \\
        
        Это означает, что такое ребро нелегально, что противоречит предположению. \\
        $\Rightarrow$ Так как триангуляция Делоне, ни одна вершина не лежит внутри описанной окружности соседнего треугольника. \\
        Следовательно, данное ребро удовлетворяет локальному критерию Делоне, то есть является легальным.
    \end{proof}

    \section{3D выпуклая оболочка. Алгоритм Джарвиса.}
    \begin{Def}
        Выпуклой оболочкой $S \subset \RR^3 \ conv(S)$ называется выпуклый
многогранник минимального объема, содержащий все точки из $S$.
    \end{Def}
    \begin{theorem}[б/д]
        Граф любого выпуклого многогранника планарен.
    \end{theorem}
    \subsection*{Алгоритм Джарвиса.}
    \begin{enumerate}
        \item Находим грань $P_i, P_j, P_k$, заведомо являющуюся гранью оболочки.
        \item Сложим ребра $P_iP_j, P_jP_k, P_kP_i$ в очередь $Q$ и запомним, что эти
        ребра уже были обработаны в множестве $T$.
        \item Пока очередь $Q$ не пуста:
        \begin{itemize}
            \item Извлекаем из $Q$ ребро $AB$
            \item Находим крайние точки относительно ребра: $C, D$ такие, что
            внутри двугранного угла $(ABC), (ABD)$ все точки
            \item Добавляем в очередь $Q$ и в множество $T$ ребра из
            $\{CA, CB, DA, DB\} \cap T$
        \end{itemize}
    \end{enumerate}
    \subsection*{Время.}
    Пусть $K$ - число вершин выпуклой оболочки, тогда время работы
$O(NK)$ - если грани только треугольные. А если нет? \\
Не треугольная грань может возникнуть, если окажется, что точки
$A, B, C, D$ на одной плоскости, тогда надо удалить ребро $AB$. Однако
таких ребер суммарно $O(K)$, так как они являются диагоналями
граней. \\
Значит время работы: $O(NK)$.
\begin{prop}[б/д]
    Существует алгоритм, строящий выпуклую оболочку $N$ точек в 3D за $O(N \log N)$.
\end{prop}

    \section{Построение триангуляции Делоне через 3D выпуклую оболочку.}
    \begin{problem}
        Дан набор $S = \{P_1, \dots , P_N\} \subset \RR^2$. Надо построить триангуляцию Делоне S.
    \end{problem}
    Перейдем в 3D и $P_i = (x_i, y_i, 0)$. Спроецируем их на параболоид $z=x^2+y^2$, то есть
    $\widetilde{P}_i =(x_i, y_i, x_i^2+y_i^2)$.
    \subsection*{Алгоритм.}
    \begin{enumerate}
        \item Построим выпуклую оболочку в 3D на точках $\{\widetilde{P}_i\}_i^N$
        \item Спроецируем нижнюю часть оболочки (нормаль к грани наружу
        направлена вниз относительно $z = 0$) на плоскость $z = 0$ -
        получим граф Делоне.
        \item Дотриангуалируем граф - получим триангуляцию Делоне.
    \end{enumerate}
    
    \section{Открытая адресация. Процедуры вставки, поиска. Артефакт \texttt{tombstone}. Время работы б/д.}
    \begin{Def}
        Открытая адресация - способ реализации хеш-таблицы, при котором все элементы хранятся внутри массива, а при коллизиях ищется другая ячейка по некоторому правилу пробирования.
    \end{Def}
    \begin{Def}
        Функция пробы $g(x, i)$ определяет положение $x$ в таблице с открытой адресацией, $i$ - номер пробы.
    \end{Def}
    \textbf{Примеры функции пробы:}
    \begin{itemize}
        \item Линейная пробирование: $g(x, i)=h(x)+i$.
        \item Квадратичное пробирование: $g(x, i)=h(x)+i^2$.
        \item Двойное хэширование: $g(x, i)=h_1(x)+ih_2(x)$.
    \end{itemize}
    \subsection*{Поиск.}
    \begin{enumerate}
        \item Вычислим $pos_i=g(x, i)\%M$. Если в $pos_i$ пусто, значит элемента
        \item Иначе:
        \begin{enumerate}
            \item Если в $pos_i$ есть элемент и он равен $x$ - нашли
            \item Если элемента нет, идем дальше к $pos_{i+1}$
        \end{enumerate}
    \end{enumerate}
    \subsection*{Вставка.}
    \begin{enumerate}
        \item Вычислим $pos_i=g(x, i)\%M$. Если в $pos_i$ пусто, вставляем
        \item Иначе:
        \begin{enumerate}
            \item Если в $pos_i$ есть элемент и он равен $x$ - закончили
            \item Если элемента нет, идем дальше к $pos_{i+1}$
        \end{enumerate}
    \end{enumerate}
    \subsection*{Удаление.}
    \begin{enumerate}
        \item Вычислим $pos_i=g(x, i)\%M$. Если в $pos_i$ пусто, закончили
        \item Иначе:
        \begin{enumerate}
            \item Если в $pos_i$ есть элемент и он равен $x$ - вставляем \texttt{tombstone}
            \item Если элемента нет, идем дальше к $pos_{i+1}$
        \end{enumerate}
    \end{enumerate}
    \subsection*{Время.}
    Рассмотрим двойное хеширование. Логично, что для фиксированного $х$ хочется, чтобы $g (x, 0), \dots, g(x, N — 1)$ образовывали перестановку от $0$ до $N — 1$. Как этого достичь? \\
Давайте считать, что число бакетов простое, тогда
\begin{align*}
    \{g(x, 0),..., g(x, N - 1)\} = \\
    &= \{h_1(x) + 0 \cdot h_2(x),\dots , h_1(x) + (N - 1) - h_2(x)\} = \\
    &= h_1(x) + h_2(x) \cdot \{0, 1,\dots, N - 1\}    
\end{align*}
Данное множество равно $\{0,..., N - 1\}$, так как сдвиг и умножение на взаимнопростое не меняет систему вычетов.
\begin{theorem}[б/д]
    В варианте выше все операции работают за $O(1)$ в среднем.
\end{theorem}

    \section{Задача Perfect hashing. Решение для static версии. Алгоритм FKS. Доказательство времени работы для первого уровня.}
    \begin{problem}[Perfect hashing]
        Структура данных, позволяющая проверять наличие элементов в множестве за $O(1)$ в худщем случае.
    \end{problem}
    \textbf{Разновидности:}
    \begin{enumerate}
        \item Static - множество задано изначально.
        \item Dynamic - можно вставлять элементы (необязательно за $O(1)$).
    \end{enumerate}
    Решаем задачу static perfect hashing для множества на $N$ элементах. \\
Хеш-таблица будет двухуровневой: хеш-таблица, где каждый бакет — хеш-таблица без коллизий.
\begin{enumerate}
    \item Выберем хеш-функцию $h_{out}$ из универсального семейства.
    \item Пусть $L_i$ - размер $i$-го из N бакетов.
    \item Если $\sum_{i=0}^{N} L^2_i > 4N$, то меняем функцию.
    \item Для каждого бакета выберем хэш-функцию $h_i$ из универсального семейства,
    число бакетов второго уровня $L_i^2$.
    \item Если $h_i$ дала коллизию, то перевыбери.
\end{enumerate}
    \subsection*{Время построение (первый уровень).}
    Посчичаем матоожидание суммы квадратов длинны цепочек:
    \begin{align*}
        &\EE \sum_{i=1}^{N} L_i^2=\EE \sum_{i=1}^{N} \left(L_i+\frac{2L_i (L_i-1)}{2}\right)=\EE \sum_{i=1}^{N} \left(L_i+2C_{L_i}^2\right) = \\
        &=\EE \sum_{i=1}^{N} L_i +2\EE \sum_{i=1}^{N} C_{L_i}^2 \leqslant \EE N +2\frac{C_N^2}{N}=N+2\frac{N-1}{2}<2N
    \end{align*}
    По неравенству Маркова
    \[P\left(\sum_{i=1}^{N} L_i^2 >4N\right)< \frac{2N}{4N}=\frac 12\]
    Таким образом, число попыток подчинено распределению $Geom(p)$,
где $p < 0.5$, откуда среднее число попыток $\leqslant 2$.

    \section{Задача Perfect hashing. Решение для static версии. Алгоритм FKS. Доказательство времени работы для второго уровня.}
    См. предыдущий
    \subsection*{Время построение (второй уровень).}
    Теперь докажем, что если строить на $L_i$ ключах таблицу на $L_i^2$ бакетов, то число коллизий мало. Пусть $\varepsilon$ - число колизий:
    \[\EE \varepsilon =\sum_{x\ne y}\EE I\left(h(x)=h(y)\right)=\sum_{x\ne y}P\left(h(x)=h(y)\right) <\sum_{x\ne y}\frac 1N\]
    \[\EE \varepsilon =\frac{C_{L_i}^2}{L_i}=\frac{L_i (L_i-1)}{2L_i^2}< \frac 12\]
    \[P(\varepsilon \geqslant 1) \leqslant \frac 12\]
    
    \section{k-независимое семейство хеш-функций. Пример. Обоснование отсутствия коллизий до взятия по модулю числа бакетов.}
    \begin{Def}
        Семейство хеш-функций $\mathcal{H}=\{h: U\rightarrow \{0, \dots, n\}\}$ называется
        $k$-независимым, если $\forall x_1\ne x_2 \ne\dots \ne x_n\in U, y_1, y_2, \dots, y_k\in \ZZ_n$
        \[P_{h\in \mathcal{H}}(h_1(x_1)=y_1, \dots, h(x_k)=y_k)\leqslant \frac{1}{n^k}\]
    \end{Def}
    То есть можно считать, что значения наборов размера $k$ хеш-функций
от ключа являются независимыми в совокупности.
    \begin{example}
        \[\mathcal{H}=h_{\alpha_0, \dots, \alpha_{k-1}}(x)=(\alpha_0 x^{k-1}+\alpha_1 x^{k-2}+\cdots + \alpha_{k-1})\mod p\]
    \end{example}
    \begin{problem}
        \begin{enumerate}
            \item Заметим, что по набору $x_i$ и $y_i$ можно однозначно восстановить $\alpha_I$, а значит на первом этапе нет коллизий. (вспоминаем FFT)
            \item Всего наборов $n^k$.
        \end{enumerate}
        \begin{center}
            \includegraphics[width=0.8\textwidth]{hash1.png}
        \end{center}
    \end{problem}

    \section{\texttt{Cuckoo hashing}. Время работы \texttt{Insert} б/д.}
    
    \begin{Def}
        Cuckoo hash-table - пара хеш-таблиц на M бакетов каждая с
хеш-функциями $h_1, h_2$.
    \end{Def}
    Данная хеш-таблица позволит решать dynamic perfect hashing.
    \subsection*{Поиск.}
    \begin{enumerate}
        \item Ищем в первой таблице. Не нашли - идем во вторую.
        \item Ищем во второй. Не нашли - элемента нет.
    \end{enumerate}
    \subsection*{Удадение.}
    Ищем, нашли - удаляем.
    \subsection*{Вставка.}
    \begin{enumerate}
        \item Пусть в $H_1$ в позиции $h_1(x)$ лежит элемент $y$, тогда положим $y$ в
        $H_2$ по позиции $h_2(y)$.
        \item Если же в $H_2$ в $h_2(y)$ лежит $z$, то переложим $z$ в $H_1$.
        \item Повторить, пока не доберемся до ячейки без элемента.
    \end{enumerate}
    Так делаем $K$ итераций. Не помогло - идем в другую сторону не от $h_1(x)$, а от $h_2(x)$. Не помогло - Rehash.
    \subsection*{Время работы.}
    Пусть $M \geqslant (1 + \varepsilon)N$, где $M$ — число бакетов, а $N$ — число элементов.
    \begin{theorem}[б/д]
        Если ограничить число итераций при вставку как $3\lceil \log{1+\varepsilon} N\rceil$, то среднее время работы вставки составит $O(1)$.
    \end{theorem}
    
    \section{Задача фильтра. Фильтр Блума. Процедура выбора гиперпараметров.}
    
    \begin{Def}
        Фильтр — вероятностная структура данных, позволяющая по
статическому множеству проверять, есть ли элемент в множестве с
свойствами:
        \begin{enumerate}
            \item Если ответ от структуры «отсутствует», то элемента в структуре
            точно нет.
            \item Если ответ от структуры «присутствует», то элемента в структуре
            может не быть.
            \item Элементы не запоминаются для экономии памяти!!
        \end{enumerate}
    \end{Def}
    \begin{Def}
        FPR (false positive rate) — вероятность rate сказать ответ
positive (элемент присутствует) и при этом сообщить ложь false.
    \end{Def}
    \begin{Def}
        Фильтр Блума — массив из $M$ битов и $k$ хеш-функций из
        $k$-независимого семейства хеш-функций.
    \end{Def}
    \subsection*{Проверка наличия.}
    \begin{enumerate}
        \item Вычислим $b_i=h_i(x)\% M$
        \item Если все $b_i = 1$, то говорим, что элемент есть в множестве.
    \end{enumerate}
    \subsection*{Считаем FPR.}
    Вероятность того, что $i$-й бит будет нулем по одной $h_j$: $1-\frac 1M$. \\
    В силу $k$-независимости оценим грубо вероятность того, что $i$-й бит
будет нулем: $\left(1-\frac 1M\right)^k$. \\
Откуда для $N$ элементов вероятность того, что $i$-й бит будет нулем: $\left(1-\frac 1M\right)^{kN}$. \\
Откуда вероятность ошибки:
\[\left(1-\left(1-\frac 1M\right)^{kN}\right)^k \approx \left(1-e^{-\frac{kN}{M}}\right)^k\]
Оптимальное $k$: $k^*=\frac MN \log 2$. Откуда $FPR=\frac{1}{2^k}$.  
    
    \section{\texttt{XOR-filter}. Алгоритм построения. Размер б/д.}
    \begin{Def}
        Гиперграфом $H = (V, E)$ называют пару из конечного множества
        вершин $V$ и конечного множества гиперребер $E$, где гиперребро —
        подмножество вершин или $\in 2^V$.
    \end{Def}
    \begin{Def}
        Степенью вершины $v$ в гиперграфе $H$ назовем число гиперребер,
в которые $v$ входит как элемент.
    \end{Def}
    \begin{Def}
        $K$-однородный гиперграф на $N$ вершинах - гиперграф на $N$
вершинах, чьи гиперребра содержат ровно $K$ вершин каждое.
    \end{Def}
    \subsection*{\texttt{XOR-filter}.}
    Введем массив $B$, в каждой ячейке которого хранится $k$-битное число
\texttt{fingerprint}. \\
Пусть будет $N$ элементов, тогда $|B| \geqslant 1.23N + 32$.
Введем три хеш-функции $h_0, h_1, h_2$ (из универсального семейства),
каждая отображает ключ $x$ в соответствующую треть диапазона от $0$
до $|B|$. \\
Цель — построить такой массив $B$, что $\forall x \in S$. \\

$B[h_0(x)] \oplus B[h_1(x)] \oplus B[h_2(x)] = fingerprint(x)$ \\
Заметим, что массив $B$ задает собой вершины, а ключ $x \in S$ задает
гиперребро на $h_i(x)$. \\
В случае универсального семейства получаем случайный
3-однородный гиперграф на $|B|$ вершинах с $N$ ребрами. \\
А надо каждой вершине назначить битовые маски длины $k$, чтобы
система была разрешима.
\subsection*{Построение.}
\begin{enumerate}
    \item Построим все гиперребра, вычислив $(h_0(x_j), h_1(x_j), h_2(x_j))$.
    \item Проведем процедуру peeling
    \begin{enumerate}
        \item Удаляем вершины степени ноль и кладем их в стек. Им рандомно
    назначим код.
        \item Удаляем вершины степени один и смежные ребра по очереди и
    кладем их в стек (декрементируя степени).
    \end{enumerate} 
    \item Если остались вершины степени 2 и выше, то у вашего
    гиперграфа имеется 2-ядро, делайте rehash.
    \item Иначе вытаскиваем вершины из стека и решаем систему
    XOR-уравнений, ставя независимым переменным рандомные
    значения.
\end{enumerate}
\begin{Def}
    $K$-ядром в однородном $R$-гиперграфе назовем индуцированный
подграф, полученный после peeling гиперграфа, состоящий из
вершин степени $\geqslant K$.
\end{Def}

    \section{\texttt{XOR-filter}. Алгоритм выбора решения.}
    См. предыдущий билет.
\end{document}

